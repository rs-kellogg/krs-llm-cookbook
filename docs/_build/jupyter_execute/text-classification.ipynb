{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "\n",
    "LLMs can replace other machine learning tasks for classification of texts. Unlike NLP models that require pre-labeled training data or a pre-defined vocabulary of words or n-grams (i.e., feature engineering), LLMs allow for zero-shot or few-shot learning to label text-like data.\n",
    "\n",
    "Examples:\n",
    "1) sentiment analysis of Yelp reviews\n",
    "2) categorize customer support requests (refund, complaint, login issues, etc.)\n",
    "3) SPAM filter\n",
    "4) Hate speech or inappropriate speech detection on social media\n",
    "5) Topic identification of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code walkthrough: labeling sentiment of Tweets regarding a specific event or hashtag\n",
    "\n",
    "For this example, we are going to assume that the Tweets (or x-eets?) have already been mined from the API. The actual process of obtaining/purchacing an API key and interacting with the API for Twitter/X is beyond the scope of this example.\n",
    "\n",
    "Below are some tweets pulled from around the time the season finale of Game of Thrones ended on May 19, 2011 that contain the hashtags #GOT or #GameOfThrones. This eight year HBO series was the cultural zeitgeist of the last decade and despite having fantastic reviews the first seven seasons, had a very controversial ending.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [\n",
    "'''\n",
    "Canâ€™t believe #GameOfThrones is coming to an end ðŸ˜­. \n",
    "This season will never take away how much love I have for this show man\n",
    "''',\n",
    "'''\n",
    "Last #GameOfThrones episode tonight.  Nervous Iâ€™ll be disappointed. \n",
    "''',\n",
    "'''\n",
    "The more I ponder, the more I ADORE WITH A PASSION #LadyOlenna of House Tyrell.\n",
    "This BADASSERY WILL NEVER BE SEEN AGAIN ON TV. #GameOfThronesFinale #GameofThrones\n",
    "''',\n",
    "'''\n",
    "When youâ€™re the only person at a GOT finale watch party \n",
    "that hasnâ€™t seen one damn episode.  #me #GOT #sundaysareforwine\n",
    "''',\n",
    "'''\n",
    "It wouldnt be so bad if they didnt make us wait an extra year. \n",
    "But they did and they fed us 6 episodes of TBS original programming quality poop! #GoT\n",
    "''',\n",
    "'''\n",
    "Based on the uproar over the ending I'm glad I never watched #GameOfThrones\n",
    "''',\n",
    "'''\n",
    "Rewatching #Gameofthrones finale. \n",
    "Dannyâ€™s speech was so awesome. So badass. \n",
    "And the unsullied with the Uruk-hai spear chant. Dope.\n",
    "''',\n",
    "'''\n",
    "Bran=Dr Strange. Both knew what had to happen to save the world, \n",
    "but neither could interfere or it would disturb the timeline. \n",
    "They also used that knowledge to encourage certain situations to \n",
    "acquire the desired outcome. #GOT #AvengersEngame\n",
    "''',\n",
    "'''\n",
    "â€œ'Game of Thrones' and star Peter Dinklage are big wins for portrayal of little people.\n",
    "\n",
    "Little people have always been stereotyped in movies and TV. \"Game of Thrones,\" \n",
    "and the character Tyrion, is a breakthroughâ€\n",
    "https://usatoday.com/story/life/2019/05/19/game-of-thrones-peter-dinklage-hero-little-people/3736538002/\n",
    "\n",
    "#GameOfThrones  #RepresentationMatters\n",
    "'''\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to organize these tweets into different categories? For example, we can ask if the person writing the tweet is a die-hard fan of the show or someone who has never watched it. We can also ask if the person has a positive, negative, or neutral reaction to the series finale.\n",
    "\n",
    "We'll use the [langchain](https://python.langchain.com/docs/get_started/introduction) software in Python to build our prompts. Langchain can interface with a number of different LLMs (including OpenAi, which we'll use in this example) and ways to chain together prompts to get the desired output.\n",
    "\n",
    "You can install the langchain module and its dependent openai module using pip.\n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "pip install openai\n",
    "```\n",
    "\n",
    "You will also want to create an environment variable containing your OpenAI API token.\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY = YOUR-TOKEN-HERE\n",
    "```\n",
    "\n",
    "You can also do this in Python.\n",
    "```python\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR TOKEN HERE'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/wkt406/openai-key.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m path_to_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/openai-key.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_to_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m/kellogg/software/miniconda3-python311/envs/llm-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/wkt406/openai-key.txt'"
     ]
    }
   ],
   "source": [
    "## read in api key from a file and export it as an environment variable\n",
    "import os\n",
    "path_to_file = os.path.expanduser('~/openai-key.txt')\n",
    "with open(path_to_file, 'r') as f:\n",
    "    os.environ['OPENAI_API_KEY'] = f.read().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt template\n",
    "\n",
    "We want to send a prompt to the AI that explains the task and the desired output. The exact format of the output can be a bit unpredictable, so sometimes it can be beneficial to provide the AI with an example or two to show it what we want.\n",
    "\n",
    "Langchain provides a nice way of designing a template for prompts with one or more variables to input into the chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(template='''\n",
    "Classify the following tweet into one of the following categories:\n",
    "\n",
    "1. Positive \n",
    "2. Negative\n",
    "3. Neutral\n",
    "\n",
    "Return the answer as a number 1, 2, or 3.\n",
    "\n",
    "===\n",
    "Example:\n",
    "Tweet: The ending of Game of Thrones was so bad. I can't believe they did that to us.\n",
    "\n",
    "Result: 2\n",
    "===\n",
    "\n",
    "Here is the Tweet:\n",
    "{tweet}\n",
    "''',\n",
    "input_variables=['tweet'],output_parser=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "for tweet in tweets:\n",
    "    prompt = template.format(tweet=tweet)\n",
    "    result = llm.predict(prompt)\n",
    "    sentiments.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These tweets are positive:\n",
      "\n",
      "Canâ€™t believe #GameOfThrones is coming to an end ðŸ˜­. \n",
      "This season will never take away how much love I have for this show man\n",
      "\n",
      "\n",
      "The more I ponder, the more I ADORE WITH A PASSION #LadyOlenna of House Tyrell.\n",
      "This BADASSERY WILL NEVER BE SEEN AGAIN ON TV. #GameOfThronesFinale #GameofThrones\n",
      "\n",
      "\n",
      "Rewatching #Gameofthrones finale. \n",
      "Dannyâ€™s speech was so awesome. So badass. \n",
      "And the unsullied with the Uruk-hai spear chant. Dope.\n",
      "\n",
      "=========================================\n",
      "These tweets are negative:\n",
      "\n",
      "Last #GameOfThrones episode tonight.  Nervous Iâ€™ll be disappointed. \n",
      "\n",
      "\n",
      "It wouldnt be so bad if they didnt make us wait an extra year. \n",
      "But they did and they fed us 6 episodes of TBS original programming quality poop! #GoT\n",
      "\n",
      "\n",
      "Based on the uproar over the ending I'm glad I never watched #GameOfThrones\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"These tweets are positive:\")\n",
    "\n",
    "for s,t, in zip(sentiments,tweets):\n",
    "    if s == '1':\n",
    "        print(t)\n",
    "        \n",
    "print(\"=========================================\")\n",
    "print(\"These tweets are negative:\")\n",
    "for s,t, in zip(sentiments,tweets):\n",
    "    if s == '2':\n",
    "        print(t)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}