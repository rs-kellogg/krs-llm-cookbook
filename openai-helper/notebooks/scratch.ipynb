{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv ../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org-EqQCXPlo5dygueWmKaAZPpPN\n",
      "proj_xWoFgRfTUrRtOPUt6KiSXidu\n",
      "sk-proj-LVIovz81KnZMDFl2vtv3T3BlbkFJlArFE63Pgd76DS3t1o3W\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"OPENAI_ORG_ID\"])\n",
    "print(os.environ[\"OPENAI_PROJ_ID\"])\n",
    "print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = openai.OpenAI(\n",
    "#     organization=os.environ[\"OPENAI_ORG_ID\"],\n",
    "#     project=os.environ[\"OPENAI_PROJ_ID\"],\n",
    "#     api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "# )\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code where logic sings,  \n",
      "A tale of recursion unfolds its wings.  \n",
      "A function calls itself, a loop divine,  \n",
      "In layers of logic, where boundaries entwine.  \n",
      "\n",
      "Imagine a mirror, reflecting your face,  \n",
      "Each glance reveals more of the same place.  \n",
      "A call to the function, a step on the way,  \n",
      "To break down a problem, come what may.  \n",
      "\n",
      "“Dear function, oh function, I need your aid,  \n",
      "To tackle this challenge, I’m somewhat dismayed.  \n",
      "But wait!” says the logic, “Let’s take a peek,  \n",
      "For this task is too grand, and solutions are bleak.”  \n",
      "\n",
      "So off goes the function, with a smaller quest,  \n",
      "A simpler version, it thinks it knows best.  \n",
      "It peeks at the problem, divides it in two,  \n",
      "And calls out again, “I’ll solve this for you!”  \n",
      "\n",
      "With each little call, like a story retold,  \n",
      "It builds up a stack, like a treasure of gold.  \n",
      "But hark! There’s a base case, a stopping decree,  \n",
      "To keep the recursion from spiraling free.  \n",
      "\n",
      "When the smallest of cases, the simplest of forms,  \n",
      "Is reached by our function, it quietly warms.  \n",
      "It starts to return, unwinding the thread,  \n",
      "Delivering answers, as logic is fed.  \n",
      "\n",
      "Oh, recursion, sweet dance of the mind’s gentle art,  \n",
      "In depths of your layers, we find where to start.  \n",
      "Though tricky at times, with pitfalls that lie,  \n",
      "The beauty in structure makes programmers sigh.  \n",
      "\n",
      "So when faced with a problem, don’t fear the recursion,  \n",
      "Embrace its deep layers, find joy in immersion.  \n",
      "For in every call, a solution takes flight,  \n",
      "In the vast world of coding, it shines ever bright.  \n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages, temperature=0.7)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image depicts a large stone head sculpture, likely an Olmec colossal head. These sculptures are known for their distinctive features and were created by the ancient Olmec civilization in Mesoamerica. The head typically represents a ruler or important figure, characterized by a flat nose, full lips, and a notable headdress or headgear. The artistic style is often seen as a significant representation of Olmec culture.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/3/31/San_Lorenzo_Monument_4_crop.jpg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvalue_survey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
